{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Test Case: Skin Disease System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:32:11.492377Z",
     "iopub.status.busy": "2025-06-13T18:32:11.492097Z",
     "iopub.status.idle": "2025-06-13T18:32:11.503327Z",
     "shell.execute_reply": "2025-06-13T18:32:11.502727Z",
     "shell.execute_reply.started": "2025-06-13T18:32:11.492357Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from transformers import SwinModel, AutoImageProcessor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:32:14.429483Z",
     "iopub.status.busy": "2025-06-13T18:32:14.428691Z",
     "iopub.status.idle": "2025-06-13T18:32:14.433457Z",
     "shell.execute_reply": "2025-06-13T18:32:14.432650Z",
     "shell.execute_reply.started": "2025-06-13T18:32:14.429458Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define constants\n",
    "unique_classes = ['Actinic_keratosis', 'Basal_cell_carcinoma', 'Benign_keratosis', \n",
    "                  'Dermatofibroma', 'Melanocytic_nevus', 'Melanoma', \n",
    "                  'Squamous_cell_carcinoma', 'Vascular_lesion']\n",
    "NUM_CLASSES = len(unique_classes)\n",
    "model_name = \"microsoft/swin-large-patch4-window7-224-in22k\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) SWIN Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:32:15.376366Z",
     "iopub.status.busy": "2025-06-13T18:32:15.376082Z",
     "iopub.status.idle": "2025-06-13T18:32:25.582302Z",
     "shell.execute_reply": "2025-06-13T18:32:25.581508Z",
     "shell.execute_reply.started": "2025-06-13T18:32:15.376346Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing and loading the trained model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af4bb0aeecc4f078774b8c74780b6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0b3c1ce89948129b0537da63c344b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/915M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d88973b8ad48cb940d6cf457a7d766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/915M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from '/kaggle/working/final_optimized_swin_model3.pth'\n",
      "Model loaded successfully and set to evaluation mode!\n",
      "\n",
      "Extracting features from: /kaggle/input/skin-disease-img/Melanoma.jpg\n",
      "Successfully loaded image: /kaggle/input/skin-disease-img/Melanoma.jpg\n",
      "Original image size: (250, 174)\n",
      "Extracted features shape: (1536,)\n",
      "Features type: <class 'numpy.ndarray'>\n",
      "\n",
      "==================================================\n",
      "FEATURE EXTRACTION COMPLETED\n",
      "==================================================\n",
      "Features shape: (1536,)\n",
      "Features dtype: float32\n",
      "First 10 feature values: [-0.11700546 -0.09721308  0.21264325 -0.1347722   0.31371462  0.23774213\n",
      " -0.21733057 -0.12520638 -0.24066457 -0.04410677]\n"
     ]
    }
   ],
   "source": [
    "# Defining the OptimizedSwinClassifier (exact copy from your original code)\n",
    "class OptimizedSwinClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=8, dropout_rate=0.3):\n",
    "        super(OptimizedSwinClassifier, self).__init__()\n",
    "        self.backbone = SwinModel.from_pretrained(model_name)\n",
    "        hidden_size = self.backbone.config.hidden_size\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.BatchNorm1d(hidden_size // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate // 2),\n",
    "            nn.Linear(hidden_size // 2, hidden_size // 4),\n",
    "            nn.BatchNorm1d(hidden_size // 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate // 4),\n",
    "            nn.Linear(hidden_size // 4, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, pixel_values):\n",
    "        outputs = self.backbone(pixel_values=pixel_values)\n",
    "        pooled_output = outputs.last_hidden_state.mean(dim=1)  \n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "    \n",
    "    def extract_features(self, pixel_values):\n",
    "        \"\"\"Extract the features before the classifier layer (after backbone + pooling)\"\"\"\n",
    "        with torch.no_grad():  \n",
    "            outputs = self.backbone(pixel_values=pixel_values)\n",
    "            pooled_output = outputs.last_hidden_state.mean(dim=1)  \n",
    "            return pooled_output.detach().cpu().numpy()\n",
    "\n",
    "def load_model(model_path):\n",
    "    print(\"Initializing and loading the trained model...\")\n",
    "    model = OptimizedSwinClassifier(num_classes=NUM_CLASSES)\n",
    "    \n",
    "    try:\n",
    "        # Loading the trained weights\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        print(f\"Successfully loaded model from '{model_path}'\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find the model file at '{model_path}'\")\n",
    "        print(\"Please check the file path and ensure the model file exists.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        raise\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    print(\"Model loaded successfully and set to evaluation mode!\")\n",
    "    return model\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Defining the same transforms used during training\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        # Loading and convert the image to RGB\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        print(f\"Successfully loaded image: {image_path}\")\n",
    "        print(f\"Original image size: {img.size}\")\n",
    "        \n",
    "        # Applying transformations\n",
    "        img_tensor = transform(img)\n",
    "        \n",
    "        # Adding batch dimension\n",
    "        img_tensor = img_tensor.unsqueeze(0)  # Shape: (1, 3, 224, 224)\n",
    "        \n",
    "        return img_tensor\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        raise\n",
    "\n",
    "def extract_image_features(model, image_path):\n",
    "    \"\"\"Extract features from a single image\"\"\"\n",
    "    print(f\"\\nExtracting features from: {image_path}\")\n",
    "    \n",
    "    # Preprocessing the image\n",
    "    img_tensor = preprocess_image(image_path)\n",
    "    \n",
    "    # Move to device\n",
    "    img_tensor = img_tensor.to(device)\n",
    "    \n",
    "    # Extracting the features\n",
    "    with torch.no_grad():\n",
    "        features = model.extract_features(img_tensor)\n",
    "    \n",
    "    # Removing the batch dimension since we only have one image\n",
    "    features = features.squeeze(0)\n",
    "    \n",
    "    print(f\"Extracted features shape: {features.shape}\")\n",
    "    print(f\"Features type: {type(features)}\")\n",
    "    \n",
    "    return features\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to demonstrate usage\"\"\"\n",
    "    \n",
    "    # Path to the SWIN model\n",
    "    model_path = \"/kaggle/working/final_optimized_swin_model3.pth\"\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # image path\n",
    "    image_path = \"/kaggle/input/skin-disease-img/Melanocytic_nevus.jpg\" \n",
    "    \n",
    "    # Checking if the image exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: Image file not found at {image_path}\")\n",
    "        print(\"Please update the image_path variable with a valid image path\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Extracting the features\n",
    "        features = extract_image_features(model, image_path)\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*50)\n",
    "        print(\"FEATURE EXTRACTION COMPLETED\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Features shape: {features.shape}\")\n",
    "        print(f\"Features dtype: {features.dtype}\")\n",
    "        print(f\"First 10 feature values: {features[:10]}\")\n",
    "        return features\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during feature extraction: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_features_batch(model, image_paths, batch_size=32):\n",
    "    \"\"\"Extract features from multiple images\"\"\"\n",
    "    all_features = []\n",
    "    \n",
    "    for i in range(0, len(image_paths), batch_size):\n",
    "        batch_paths = image_paths[i:i+batch_size]\n",
    "        batch_tensors = []\n",
    "        \n",
    "        for img_path in batch_paths:\n",
    "            try:\n",
    "                img_tensor = preprocess_image(img_path)\n",
    "                batch_tensors.append(img_tensor.squeeze(0))  # Remove batch dim for stacking\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {img_path} due to error: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if batch_tensors:\n",
    "            # Stacking into batch\n",
    "            batch_tensor = torch.stack(batch_tensors).to(device)\n",
    "            \n",
    "            # Extracting the features\n",
    "            with torch.no_grad():\n",
    "                batch_features = model.extract_features(batch_tensor)\n",
    "            \n",
    "            all_features.append(batch_features)\n",
    "            \n",
    "            # Clear the GPU cache periodically\n",
    "            if i % (batch_size * 10) == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    if all_features:\n",
    "        return np.concatenate(all_features, axis=0)\n",
    "    else:\n",
    "        return np.array([])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:54:49.480518Z",
     "iopub.status.busy": "2025-06-13T18:54:49.480229Z",
     "iopub.status.idle": "2025-06-13T18:54:49.484672Z",
     "shell.execute_reply": "2025-06-13T18:54:49.483881Z",
     "shell.execute_reply.started": "2025-06-13T18:54:49.480497Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:54:54.490071Z",
     "iopub.status.busy": "2025-06-13T18:54:54.489791Z",
     "iopub.status.idle": "2025-06-13T18:54:54.494857Z",
     "shell.execute_reply": "2025-06-13T18:54:54.494004Z",
     "shell.execute_reply.started": "2025-06-13T18:54:54.490051Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loading the Random Forest model\n",
    "def load_rf_model(model_path):\n",
    "    \"\"\"Load the trained Random Forest model\"\"\"\n",
    "    try:\n",
    "        print(f\"Loading Random Forest model from: {model_path}\")\n",
    "        rf_model = joblib.load(model_path)\n",
    "        print(\"Random Forest model loaded successfully!\")\n",
    "        return rf_model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Random Forest model: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:54:56.845230Z",
     "iopub.status.busy": "2025-06-13T18:54:56.844958Z",
     "iopub.status.idle": "2025-06-13T18:54:57.398732Z",
     "shell.execute_reply": "2025-06-13T18:54:57.398158Z",
     "shell.execute_reply.started": "2025-06-13T18:54:56.845211Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available anatomic sites:\n",
      "  1. anterior torso\n",
      "  2. head/neck\n",
      "  3. lower extremity\n",
      "  4. oral/genital\n",
      "  5. palms/soles\n",
      "  6. posterior torso\n",
      "  7. upper extremity\n",
      "============================================================\n",
      "RUNNING DISEASE PREDICTION PIPELINE\n",
      "============================================================\n",
      "Loading Random Forest model from: /kaggle/input/rf_best_model/tensorflow2/default/1/best_rf_model.pkl\n",
      "Random Forest model loaded successfully!\n",
      "Created metadata for:\n",
      "  Age: 45 (range: 41-50)\n",
      "  Gender: female\n",
      "  Anatomic site: anterior torso\n",
      "Combined input shape: (1, 1553)\n",
      "Image features: 1536 dimensions\n",
      "Metadata features: 17 dimensions\n",
      "\n",
      "Prediction Results:\n",
      "========================================\n",
      "Predicted Disease: Melanocytic_nevus\n",
      "Confidence: 0.1619\n",
      "\n",
      "All Class Probabilities:\n",
      "------------------------------\n",
      "Melanocytic_nevus: 0.1619\n",
      "Squamous_cell_carcinoma: 0.1595\n",
      "Actinic_keratosis: 0.1430\n",
      "Dermatofibroma: 0.1216\n",
      "Benign_keratosis: 0.1173\n",
      "Vascular_lesion: 0.1117\n",
      "Melanoma: 0.0958\n",
      "Basal_cell_carcinoma: 0.0892\n",
      "============================================================\n",
      "PIPELINE COMPLETED SUCCESSFULLY\n",
      "============================================================\n",
      "\n",
      "Final Result: The predicted disease is 'Melanocytic_nevus'\n"
     ]
    }
   ],
   "source": [
    "# Creating the user metadata input structure\n",
    "def create_user_metadata_input(age, gender, anatomic_site):\n",
    "    # Defining all the possible anatomic sites from the training data\n",
    "    anatomic_sites = [\n",
    "        'anterior torso', 'head/neck', 'lower extremity', \n",
    "        'oral/genital', 'palms/soles', 'posterior torso', 'upper extremity'\n",
    "    ]\n",
    "    \n",
    "    # Defining the age ranges\n",
    "    age_ranges = [\n",
    "        '1-10', '11-20', '21-30', '31-40', \n",
    "        '41-50', '51-60', '61-70', '71-90'\n",
    "    ]\n",
    "    \n",
    "    # Validating the inputs\n",
    "    if gender.lower() not in ['male', 'female']:\n",
    "        raise ValueError(\"Gender must be 'male' or 'female'\")\n",
    "    \n",
    "    if anatomic_site not in anatomic_sites:\n",
    "        raise ValueError(f\"Anatomic site must be one of: {anatomic_sites}\")\n",
    "    \n",
    "    # Determining the age range\n",
    "    if age <= 10:\n",
    "        age_range = '1-10'\n",
    "    elif age <= 20:\n",
    "        age_range = '11-20'\n",
    "    elif age <= 30:\n",
    "        age_range = '21-30'\n",
    "    elif age <= 40:\n",
    "        age_range = '31-40'\n",
    "    elif age <= 50:\n",
    "        age_range = '41-50'\n",
    "    elif age <= 60:\n",
    "        age_range = '51-60'\n",
    "    elif age <= 70:\n",
    "        age_range = '61-70'\n",
    "    else:\n",
    "        age_range = '71-90'\n",
    "    \n",
    "    # Creating the metadata dictionary\n",
    "    metadata = {}\n",
    "    \n",
    "    # Initializing all the anatomic site columns to 0\n",
    "    for site in anatomic_sites:\n",
    "        metadata[f'site_{site}'] = 0\n",
    "    \n",
    "    # Seting the user's anatomic site to 1\n",
    "    metadata[f'site_{anatomic_site}'] = 1\n",
    "    \n",
    "    # Initializ ing all the gender columns to 0\n",
    "    metadata['sex_female'] = 0\n",
    "    metadata['sex_male'] = 0\n",
    "    \n",
    "    # Seting the user's gender to 1\n",
    "    if gender.lower() == 'female':\n",
    "        metadata['sex_female'] = 1\n",
    "    else:\n",
    "        metadata['sex_male'] = 1\n",
    "    \n",
    "    # Initializing all the  age range columns to 0\n",
    "    for age_r in age_ranges:\n",
    "        metadata[f'age_{age_r}'] = 0\n",
    "    \n",
    "    # Seting the user's age range to 1\n",
    "    metadata[f'age_{age_range}'] = 1\n",
    "    \n",
    "    # Converting to DataFrame\n",
    "    metadata_df = pd.DataFrame([metadata])\n",
    "    \n",
    "    print(f\"Created metadata for:\")\n",
    "    print(f\"  Age: {age} (range: {age_range})\")\n",
    "    print(f\"  Gender: {gender}\")\n",
    "    print(f\"  Anatomic site: {anatomic_site}\")\n",
    "    \n",
    "    return metadata_df\n",
    "\n",
    "# Combining the image features with the user metadata\n",
    "def combine_features_metadata(image_features, user_metadata_df):    \n",
    "    # Convert image features to DataFrame\n",
    "    feature_cols = [f\"feature_{i}\" for i in range(len(image_features))]\n",
    "    features_df = pd.DataFrame([image_features], columns=feature_cols)\n",
    "    \n",
    "    # Combining the features with the metadata\n",
    "    combined_input = pd.concat([user_metadata_df.reset_index(drop=True), \n",
    "                               features_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    print(f\"Combined input shape: {combined_input.shape}\")\n",
    "    print(f\"Image features: {len(image_features)} dimensions\")\n",
    "    print(f\"Metadata features: {user_metadata_df.shape[1]} dimensions\")\n",
    "    \n",
    "    return combined_input\n",
    "\n",
    "# Making the prediction by using the Random Forest model\n",
    "def predict_disease(rf_model, combined_input):    \n",
    "    try:\n",
    "        # Making prediction\n",
    "        prediction = rf_model.predict(combined_input)\n",
    "        prediction_proba = rf_model.predict_proba(combined_input)\n",
    "        \n",
    "        # Geting the class names\n",
    "        class_names = rf_model.classes_\n",
    "        \n",
    "        # Geting the predicted disease\n",
    "        predicted_disease = prediction[0]\n",
    "        \n",
    "        # Geting the prediction probabilities\n",
    "        prob_dict = {class_names[i]: prediction_proba[0][i] for i in range(len(class_names))}\n",
    "        \n",
    "        print(f\"\\nPrediction Results:\")\n",
    "        print(\"=\" * 40)\n",
    "        print(f\"Predicted Disease: {predicted_disease}\")\n",
    "        print(f\"Confidence: {prob_dict[predicted_disease]:.4f}\")\n",
    "        \n",
    "        print(f\"\\nAll Class Probabilities:\")\n",
    "        print(\"-\" * 30)\n",
    "        for disease, prob in sorted(prob_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"{disease}: {prob:.4f}\")\n",
    "        \n",
    "        return predicted_disease\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error making prediction: {e}\")\n",
    "        raise\n",
    "\n",
    "# The Main pipeline function\n",
    "def run_prediction_pipeline(rf_model_path, image_features, age, gender, anatomic_site):    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"RUNNING DISEASE PREDICTION PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Loading the RF model\n",
    "    rf_model = load_rf_model(rf_model_path)\n",
    "    \n",
    "    # Creating the user metadata\n",
    "    user_metadata = create_user_metadata_input(age, gender, anatomic_site)\n",
    "    \n",
    "    # Combining the features with the metadata\n",
    "    combined_input = combine_features_metadata(image_features, user_metadata)\n",
    "    \n",
    "    # Making the prediction\n",
    "    predicted_disease = predict_disease(rf_model, combined_input)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"PIPELINE COMPLETED SUCCESSFULLY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return predicted_disease\n",
    "\n",
    "def example_usage():  \n",
    "    \n",
    "    rf_model_path = \"/kaggle/input/rf_best_model/tensorflow2/default/1/best_rf_model.pkl\"\n",
    "    \n",
    "    example_features = np.random.randn(1536)  \n",
    "    \n",
    "    # Example of the user metadata \n",
    "    user_age = 45\n",
    "    user_gender = \"female\" \n",
    "    user_anatomic_site = \"anterior torso\"  \n",
    "    \n",
    "    # The anatomic sites:\n",
    "    available_sites = [\n",
    "        'anterior torso', 'head/neck', 'lower extremity', \n",
    "        'oral/genital', 'palms/soles', 'posterior torso', 'upper extremity'\n",
    "    ]\n",
    "    \n",
    "    print(\"Available anatomic sites:\")\n",
    "    for i, site in enumerate(available_sites, 1):\n",
    "        print(f\"  {i}. {site}\")\n",
    "    \n",
    "    try:\n",
    "        # Runing the prediction pipeline\n",
    "        predicted_disease = run_prediction_pipeline(\n",
    "            rf_model_path=rf_model_path,\n",
    "            image_features=example_features,\n",
    "            age=user_age,\n",
    "            gender=user_gender,\n",
    "            anatomic_site=user_anatomic_site\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nFinal Result: The predicted disease is '{predicted_disease}'\")\n",
    "        return predicted_disease\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in prediction pipeline: {e}\")\n",
    "        return None\n",
    "\n",
    "# A function to get the user input interactively (But I didn't used it in this test case)\n",
    "def get_user_input():  \n",
    "    print(\"Please provide the following information:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Get age\n",
    "    while True:\n",
    "        try:\n",
    "            age = int(input(\"Enter patient age (1-90): \"))\n",
    "            if 1 <= age <= 90:\n",
    "                break\n",
    "            else:\n",
    "                print(\"Age must be between 1 and 90\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid number\")\n",
    "    \n",
    "    # Geting the gender\n",
    "    while True:\n",
    "        gender = input(\"Enter patient gender (male/female): \").lower().strip()\n",
    "        if gender in ['male', 'female']:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Please enter 'male' or 'female'\")\n",
    "    \n",
    "    # Geting the anatomic site\n",
    "    sites = [\n",
    "        'anterior torso', 'head/neck', 'lower extremity', \n",
    "        'oral/genital', 'palms/soles', 'posterior torso', 'upper extremity'\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nAvailable anatomic sites:\")\n",
    "    for i, site in enumerate(sites, 1):\n",
    "        print(f\"  {i}. {site}\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            site_choice = int(input(\"Enter anatomic site number (1-7): \"))\n",
    "            if 1 <= site_choice <= 7:\n",
    "                anatomic_site = sites[site_choice - 1]\n",
    "                break\n",
    "            else:\n",
    "                print(\"Please enter a number between 1 and 7\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid number\")\n",
    "    \n",
    "    return age, gender, anatomic_site\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Runing the example\n",
    "    example_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Multi Agent System "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-13T19:08:58.769557Z",
     "iopub.status.busy": "2025-06-13T19:08:58.768962Z",
     "iopub.status.idle": "2025-06-13T19:09:08.966239Z",
     "shell.execute_reply": "2025-06-13T19:09:08.965467Z",
     "shell.execute_reply.started": "2025-06-13T19:08:58.769532Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.22)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.4.8-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.23-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain)\n",
      "  Downloading langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.23)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
      "Collecting langgraph-checkpoint>=2.0.26 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-prebuilt>=0.2.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.2.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.70-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.70.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
      "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint>=2.0.26->langgraph)\n",
      "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langgraph-0.4.8-py3-none-any.whl (152 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.3.23-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.65-py3-none-any.whl (438 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.1/438.1 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langgraph_prebuilt-0.2.2-py3-none-any.whl (23 kB)\n",
      "Downloading langgraph_sdk-0.1.70-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: packaging, ormsgpack, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langgraph-prebuilt, langchain, langgraph\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.3.23\n",
      "    Uninstalling langsmith-0.3.23:\n",
      "      Successfully uninstalled langsmith-0.3.23\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.50\n",
      "    Uninstalling langchain-core-0.3.50:\n",
      "      Successfully uninstalled langchain-core-0.3.50\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.3.7\n",
      "    Uninstalling langchain-text-splitters-0.3.7:\n",
      "      Successfully uninstalled langchain-text-splitters-0.3.7\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.22\n",
      "    Uninstalling langchain-0.3.22:\n",
      "      Successfully uninstalled langchain-0.3.22\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "pandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-0.3.25 langchain-core-0.3.65 langchain-openai-0.3.23 langchain-text-splitters-0.3.8 langgraph-0.4.8 langgraph-checkpoint-2.0.26 langgraph-prebuilt-0.2.2 langgraph-sdk-0.1.70 langsmith-0.3.45 ormsgpack-1.10.0 packaging-24.2\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if not already installed\n",
    "!pip install --upgrade langchain langgraph langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T19:09:08.967883Z",
     "iopub.status.busy": "2025-06-13T19:09:08.967585Z",
     "iopub.status.idle": "2025-06-13T19:09:11.546958Z",
     "shell.execute_reply": "2025-06-13T19:09:11.546184Z",
     "shell.execute_reply.started": "2025-06-13T19:09:08.967859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict\n",
    "import re\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T19:25:22.344442Z",
     "iopub.status.busy": "2025-06-13T19:25:22.343831Z",
     "iopub.status.idle": "2025-06-13T19:25:36.398789Z",
     "shell.execute_reply": "2025-06-13T19:25:36.397950Z",
     "shell.execute_reply.started": "2025-06-13T19:25:22.344419Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your country to find hospitals:  England\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Medical Assistant...\n",
      "\n",
      "\n",
      "==============================\n",
      "Information About: Melanocytic_nevus\n",
      "==============================\n",
      "Melanocytic nevus, commonly known as a mole, is a benign skin growth that develops when melanocytes (cells that produce pigment) grow in clusters. These moles can vary in color, size, and shape, and are usually harmless. However, they should be monitored for any changes in appearance that could indicate skin cancer.\n",
      "\n",
      "Symptoms: Typically, melanocytic nevi appear as small, dark brown spots on the skin. They can be flat or raised, and may have a smooth or rough texture.\n",
      "\n",
      "Causes: The exact cause of melanocytic nevi is not fully understood, but they are believed to be influenced by genetic factors and sun exposure.\n",
      "\n",
      "Possible treatments: In most cases, no treatment is needed for melanocytic nevi. However, if a mole shows signs of change or is at risk of becoming cancerous, it may need to be removed surgically. Regular skin checks and monitoring by a dermatologist are recommended for individuals with a large number of moles or a family history of skin cancer.\n",
      "\n",
      "==============================\n",
      "Hospitals in England\n",
      "==============================\n",
      "1. St. John's Institute of Dermatology\n",
      "City: London\n",
      "Contact Number: +44 20 7188 6410\n",
      "Address: Guy's Hospital, Great Maze Pond, London SE1 9RT\n",
      "\n",
      "2. The London Skin and Hair Clinic\n",
      "City: London\n",
      "Contact Number: +44 20 7183 4565\n",
      "Address: 233 High Holborn, London WC1V 7DN\n",
      "\n",
      "3. The Cadogan Clinic\n",
      "City: London\n",
      "Contact Number: +44 20 7901 8500\n",
      "Address: 120 Sloane Street, London SW1X 9BW\n",
      "\n",
      "4. The Harley Street Dermatology Clinic\n",
      "City: London\n",
      "Contact Number: +44 20 7034 5999\n",
      "Address: 48 Harley Street, London W1G 9PU\n",
      "\n",
      "5. The Dermatology Clinic London\n",
      "City: London\n",
      "Contact Number: +44 20 7435 7521\n",
      "Address: 233 High Holborn, London WC1V 7DN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.environ['OPENROUTER_API_KEY'] = \"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\"  # <-- Replace with your key\n",
    "\n",
    "class MedicalState(TypedDict):\n",
    "    disease: str\n",
    "    country: str\n",
    "    disease_info: str\n",
    "    hospital_list: str\n",
    "\n",
    "class AgentMemory:\n",
    "    def __init__(self):\n",
    "        self.chat_log = []\n",
    "    \n",
    "    def update(self, message: str):\n",
    "        self.chat_log.append(message)\n",
    "    \n",
    "    def get_context(self, n=5):\n",
    "        return \"\\n\".join(self.chat_log[-n:])\n",
    "\n",
    "memory = AgentMemory()\n",
    "\n",
    "\n",
    "def get_llm(model: str = \"gpt-3.5-turbo\", temp: float = 0.2):\n",
    "    return ChatOpenAI(\n",
    "        openai_api_key=os.environ['OPENROUTER_API_KEY'],\n",
    "        openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "        model=model,\n",
    "        temperature=temp,\n",
    "        max_retries=3,\n",
    "        timeout=30\n",
    "    )\n",
    "\n",
    "def disease_info_agent(state: MedicalState) -> MedicalState:\n",
    "    prompt = f\"\"\"You are a helpful medical assistant.\n",
    "Provide a clear and concise 4–5 sentence description of the skin disease \"{state['disease']}\" and after that only mention the following briefly in this format: \n",
    "1- its symptoms: \n",
    "2- its causes:\n",
    "3- the possible treatments:.\n",
    "\n",
    "Disease: {state['disease']}\n",
    "Description:\"\"\"\n",
    "\n",
    "    llm = get_llm(\"gpt-3.5-turbo\", 0.2)\n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=\"You are a reliable, medically informed assistant.\"),\n",
    "        HumanMessage(content=prompt)\n",
    "    ]).content\n",
    "    \n",
    "    memory.update(f\"Disease Info: {response}\")\n",
    "    return {**state, \"disease_info\": response}\n",
    "\n",
    "def hospital_finder_agent(state: MedicalState) -> MedicalState:\n",
    "    prompt = f\"\"\"List 5 well-known hospitals or dermatology clinics in {state['country']} where someone can go for treatment of a skin disease.\n",
    "Include their:\n",
    "- name\n",
    "- city\n",
    "- contact number (if possible)\n",
    "- a short address\n",
    "\n",
    "Only show relevant institutions with a reputation for dermatology or skin care.\"\"\"\n",
    "\n",
    "    llm = get_llm(\"gpt-3.5-turbo\", 0.2)\n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=\"You are a medical travel assistant helping people find hospitals.\"),\n",
    "        HumanMessage(content=prompt)\n",
    "    ]).content\n",
    "    \n",
    "    memory.update(f\"Hospital Info: {response}\")\n",
    "    return {**state, \"hospital_list\": response}\n",
    "\n",
    "def build_workflow():\n",
    "    graph = StateGraph(MedicalState)\n",
    "    graph.add_node(\"describe_disease\", disease_info_agent)\n",
    "    graph.add_node(\"find_hospitals\", hospital_finder_agent)\n",
    "    graph.set_entry_point(\"describe_disease\")\n",
    "    graph.add_edge(\"describe_disease\", \"find_hospitals\")\n",
    "    graph.add_edge(\"find_hospitals\", END)\n",
    "    return graph.compile()\n",
    "\n",
    "def medical_assistant(disease: str, country: str):\n",
    "    initial_state = {\n",
    "        \"disease\": disease.strip(),\n",
    "        \"country\": country.strip(),\n",
    "        \"disease_info\": \"\",\n",
    "        \"hospital_list\": \"\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        assistant = build_workflow()\n",
    "        final_state = assistant.invoke(initial_state)\n",
    "\n",
    "        output = f\"\"\"\n",
    "==============================\n",
    "Information About: {final_state['disease']}\n",
    "==============================\n",
    "{final_state['disease_info']}\n",
    "\n",
    "==============================\n",
    "Hospitals in {final_state['country']}\n",
    "==============================\n",
    "{final_state['hospital_list']}\n",
    "\"\"\"\n",
    "        return output\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "\n",
    "\n",
    "# Giving it the Diagnosed Disease (the Melanocytic_nevus)\n",
    "if __name__ == \"__main__\":\n",
    "    disease = 'Melanocytic_nevus'\n",
    "    country = input(\"Enter your country to find hospitals: \")\n",
    "\n",
    "    print(\"\\nRunning Medical Assistant...\\n\")\n",
    "    result = medical_assistant(disease, country)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 54339,
     "sourceId": 104884,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7110226,
     "sourceId": 11360411,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7592492,
     "sourceId": 12062552,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7592498,
     "sourceId": 12062561,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7592641,
     "sourceId": 12062793,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7595042,
     "sourceId": 12066576,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7657262,
     "sourceId": 12158111,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 375622,
     "modelInstanceId": 354309,
     "sourceId": 434484,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 375625,
     "modelInstanceId": 354312,
     "sourceId": 434487,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
